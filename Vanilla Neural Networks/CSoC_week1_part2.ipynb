{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "G21XGCYGtn14"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_recall_curve, auc, confusion_matrix\n",
        "import psutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "try:\n",
        "        drive.mount('/content/drive')\n",
        "except Exception as e:\n",
        "        print(f\"An error occurred during mounting: {e}\")\n",
        "\n",
        "import zipfile\n",
        "zip_path = '/content/drive/MyDrive/KaggleV2-May-2016.csv.zip'\n",
        "extract_path = '/content/drive/MyDrive/'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIm2zUsuvBH-",
        "outputId": "0159fce0-f7c8-4e48-e119-4d22b6e3ebbe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, in_features, h1, h2, out_features):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(in_features, h1)\n",
        "    self.fc2 = nn.Linear(h1, h2)\n",
        "    self.fc3 = nn.Linear(h2, out_features)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.softmax(self.fc3(x),dim = 1)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "ifIzrGs9YQ2x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/KaggleV2-May-2016.csv')\n",
        "\n",
        "\n",
        "df=df.drop(columns=['PatientId','AppointmentID','ScheduledDay','AppointmentDay',])\n",
        "df.rename(columns={'No-show':'given'},inplace = True)\n",
        "df['given'] = df['given'].map({'No':0,'Yes':1})\n",
        "df['Gender'] = df['Gender'].map({'F':0,'M':1})\n",
        "\n",
        "df = pd.get_dummies(df, columns=[\"Neighbourhood\"])\n",
        "\n",
        "features = ['Gender', 'Age', 'Scholarship', 'Hipertension',\n",
        "            'Diabetes', 'Alcoholism', 'Handcap', 'SMS_received'] + [col for col in df.columns if col.startswith(\"Neighbourhood_\")]\n",
        "\n",
        "X = df[features].values\n",
        "y = df['given'].values\n",
        "\n",
        "SS_X = StandardScaler()\n",
        "X = SS_X.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "input_size = X_train.shape[1]\n",
        "model=Model(input_size,64,32,2)\n",
        "\n",
        "class_counts = np.bincount(y_train.numpy())\n",
        "class_weights = torch.tensor([1.0 / class_counts[0], 1.0 / class_counts[1]], dtype=torch.float32)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimiser = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "epochs = 200\n",
        "losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  y_pred = model.forward(X_train)\n",
        "  loss = criterion(y_pred, y_train)\n",
        "  losses.append(loss.detach().numpy())\n",
        "  if i % 10 == 0:\n",
        "    print(f'Epoch {i} loss is {loss}')\n",
        "  optimiser.zero_grad()\n",
        "  loss.backward()\n",
        "  optimiser.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij0VrwhcnQ24",
        "outputId": "03d0854d-c015-4eb3-b282-972684235a73",
        "collapsed": true
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 loss is 0.6941185593605042\n",
            "Epoch 10 loss is 0.6935303211212158\n",
            "Epoch 20 loss is 0.6930410265922546\n",
            "Epoch 30 loss is 0.6926124095916748\n",
            "Epoch 40 loss is 0.692211389541626\n",
            "Epoch 50 loss is 0.69181227684021\n",
            "Epoch 60 loss is 0.6914030313491821\n",
            "Epoch 70 loss is 0.6909701228141785\n",
            "Epoch 80 loss is 0.6905131936073303\n",
            "Epoch 90 loss is 0.6900309920310974\n",
            "Epoch 100 loss is 0.6895164251327515\n",
            "Epoch 110 loss is 0.6889621019363403\n",
            "Epoch 120 loss is 0.688359797000885\n",
            "Epoch 130 loss is 0.6877023577690125\n",
            "Epoch 140 loss is 0.6869978904724121\n",
            "Epoch 150 loss is 0.6862664818763733\n",
            "Epoch 160 loss is 0.6855141520500183\n",
            "Epoch 170 loss is 0.6847543716430664\n",
            "Epoch 180 loss is 0.6839889883995056\n",
            "Epoch 190 loss is 0.6832241415977478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "LgUrHdgixp5D"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Handle binary or multiclass classification based on output shape\n",
        "            if outputs.shape[1] > 1: # If output shape is greater than 1, it's likely multiclass or binary with two outputs\n",
        "                # For models with 2 outputs for binary classification (like yours with softmax)\n",
        "                # The predicted class is the index with the highest probability\n",
        "                probs = outputs # Since your model uses softmax, outputs are already probabilities\n",
        "                preds = torch.argmax(outputs, dim=1) # Get the index of the max probability\n",
        "\n",
        "            elif outputs.shape[1] == 1: # This case is for models with a single output for binary classification (e.g., using sigmoid)\n",
        "                probs = torch.sigmoid(outputs).squeeze()\n",
        "                preds = (probs > 0.5).int()\n",
        "            else:\n",
        "                 raise ValueError(f\"Unexpected output shape: {outputs.shape}\")\n",
        "\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # For probabilities, if it's binary with two outputs, we often care about the probability of the positive class (index 1)\n",
        "            if outputs.shape[1] > 1:\n",
        "                # Assuming class 1 is the positive class\n",
        "                all_probs.extend(probs[:, 1].cpu().numpy())\n",
        "            elif outputs.shape[1] == 1:\n",
        "                 all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "\n",
        "    return np.array(all_preds), np.array(all_labels), np.array(all_probs)"
      ],
      "metadata": {
        "id": "Y95O5DEmvkQV"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(y_true, y_pred, y_probs, multiclass=False):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted' if multiclass else 'binary')\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    if not multiclass:\n",
        "        precision, recall, _ = precision_recall_curve(y_true, y_probs)\n",
        "        pr_auc = auc(recall, precision)\n",
        "    return acc, f1, pr_auc, cm\n"
      ],
      "metadata": {
        "id": "nsVoPnpiwFWa"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_memory_usage():\n",
        "    process = psutil.Process()\n",
        "    mem_info = process.memory_info()\n",
        "    memory_used_mb = mem_info.rss / 1024 ** 2\n",
        "    return memory_used_mb"
      ],
      "metadata": {
        "id": "FsP--yB_wVc3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "y_pred, y_true, y_probs = evaluate_model(model, test_loader, device)\n",
        "\n",
        "multiclass = len(np.unique(y_true)) > 2\n",
        "pr_auc_input = y_probs if not multiclass else None\n",
        "acc, f1, pr_auc, cm = calculate_metrics(y_true, y_pred, pr_auc_input, multiclass)\n",
        "\n",
        "mem_used = get_memory_usage()\n",
        "\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "if pr_auc is not None:\n",
        "    print(f\"PR AUC: {pr_auc:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(f\"Memory Usage: {mem_used:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "triHFo99wbns",
        "outputId": "7e9a4dd3-c028-4082-efa4-e6f85d81421d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5606\n",
            "F1 Score: 0.3434\n",
            "PR AUC: 0.2645\n",
            "Confusion Matrix:\n",
            "[[9852 7817]\n",
            " [1897 2540]]\n",
            "Memory Usage: 2095.13 MB\n"
          ]
        }
      ]
    }
  ]
}